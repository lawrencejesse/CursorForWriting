# The AI Revolution: The Road to Superintelligence

**Author:** Tim Urban (Wait But Why)  
**Published:** January 22, 2015  
**Source:** https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html  
**Saved:** 2025-02-26  

**Why It Matters:** This two-part blog post fundamentally shaped my understanding of AI progress and potential. Urban's explanations of exponential growth and the concept of superintelligence made abstract concepts concrete and helped me think more clearly about technological development timelines.

---

[Note: This is just a brief excerpt from the much longer original post]

We're on the edge of change comparable to the rise of human life on Earth. — Vernor Vinge

The Road to Superintelligence

Artificial Intelligence is the field that studies how to create computers and software that are capable of intelligent behavior. The field was founded on the claim that a central property of humans, intelligence—the sapience of Homo sapiens—can be so precisely described that it can be simulated by a machine. This raises philosophical issues about the nature of the mind and the ethics of creating artificial beings endowed with human-like intelligence, issues which have been addressed by myth, fiction and philosophy since antiquity.

[...]

What would happen if we created a computer that was more intelligent than humans?

If an AI system is just a little smarter than a human, it can read all of human literature, understand it, and then write better literature than humans can. If it's a little smarter than that, it can solve problems in physics and mathematics that no human has been able to solve. And if it's a little smarter than that, it can invent new technologies that no human would be able to invent.

[...]

The reason is that human progress grows exponentially, not linearly. The rate of progress is itself accelerating. We're not going from 1 to 2 to 3 to 4. We're going from 1 to 2 to 4 to 8. And the numbers get so big so quickly that our human brains can't intuitively understand them.

[...]

---

## My Notes

This blog post introduced me to several key concepts:

1. **The Law of Accelerating Returns** - Technology progresses exponentially, not linearly, which makes predictions difficult because humans think linearly

2. **Intelligence Explosion** - Once AI reaches human-level intelligence, it could rapidly improve itself, leading to superintelligence in a short time

3. **The Hard Takeoff Scenario** - The transition from human-level AI to superintelligence could happen very quickly, potentially over days or weeks rather than years

What I found most valuable was Urban's ability to make these complex topics accessible through analogies and visualizations. The "Die Progress Unit" (measuring progress by how many people would "die from shock" if transported to a different time) was particularly effective.

I've revisited this post several times when thinking about technology development timelines and the potential impacts of AI. It's a reminder that exponential progress means the future may arrive much sooner than linear thinking would suggest.

## Related Ideas

- @ideas/sparks/20250226_ai_augmented_creativity.md - There's an interesting connection here to how we might collaborate with increasingly capable AI systems before superintelligence.

- This connects to the concept of "AI alignment" - ensuring that superintelligent systems share human values and goals.

## Tags
#ai #superintelligence #exponential-growth #technology #futurism #tim-urban 